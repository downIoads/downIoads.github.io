<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>ai on Blog for Tech Enjoyers</title>
    <link>https://example.com/tags/ai/</link>
    <description>Recent content in ai on Blog for Tech Enjoyers</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 20 Oct 2023 22:50:00 +0200</lastBuildDate>
    <atom:link href="https://example.com/tags/ai/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Using Stable Diffusion as Discord Emote Generator</title>
      <link>https://example.com/posts/stable-diffusion-gopher/</link>
      <pubDate>Fri, 20 Oct 2023 22:50:00 +0200</pubDate>
      <guid>https://example.com/posts/stable-diffusion-gopher/</guid>
      <description>Introduction Stable Diffusion is an open-source deep learning text-to-image model that does not have any filters and works offline. There are a few controversies around it (e.g., it has been trained on copyrighted artwork but gives the user of Stable Diffusion the rights to all images it spits out, and it does not have filters and can be used to create all sorts of weird content). It works offline and poses a threat to existing businesses that sell AI-generated images (e.</description>
    </item>
    <item>
      <title>Python script for Llama 2 conversations</title>
      <link>https://example.com/posts/llama-python/</link>
      <pubDate>Wed, 26 Jul 2023 18:00:23 +0200</pubDate>
      <guid>https://example.com/posts/llama-python/</guid>
      <description>Introduction I have played around a bit with the new Llama 2 LLM, more specifically with the 13B parameter Huggingface version that you can download here. In order to run it, check out Llama.cpp. It has precise setup instructions, so I will assume you get that running on your own. What I did not enjoy was having to type long commands into my Windows cmd every time, so I decided to write a short Python script that runs the process in the background and displays the output in the Python shell in real-time (well, almost).</description>
    </item>
  </channel>
</rss>
